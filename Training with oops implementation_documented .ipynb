{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1af66877",
   "metadata": {},
   "source": [
    "# Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88d563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import neattext.functions as nfx\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline \n",
    "import string \n",
    "import re\n",
    "import nltk\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf97325",
   "metadata": {},
   "source": [
    "# Imporing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4e29449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier \n",
    "from sklearn.linear_model import SGDClassifier \n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7434ba5a",
   "metadata": {},
   "source": [
    "# Importing Preprocessing mathods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7521dd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix as score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3aaf615d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97724b85",
   "metadata": {},
   "source": [
    "# creating the trainpredict class\n",
    "\n",
    "- > The class contains the models which  can train with data and also predict the test data and give the metrics , all at once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b45bc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndPredict:\n",
    "    \n",
    "    def __init__(self, train, test, vect_train, vect_test, target):\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.vect_train = vect_train\n",
    "        self.vect_test = vect_test\n",
    "        self.target = target\n",
    "        \n",
    "    def RandomForestClassifier(self):\n",
    "        \n",
    "        rf = RandomForestClassifier(n_estimators=150, max_depth=None, n_jobs=-1)\n",
    "\n",
    "        start = time.time()\n",
    "        rf_model = rf.fit(pd.DataFrame(self.vect_train), self.train[self.target])\n",
    "        end = time.time()\n",
    "        fit_time = (end - start)\n",
    "        \n",
    "        start = time.time()\n",
    "        y_pred = rf_model.predict(pd.DataFrame(self.vect_test))\n",
    "        end = time.time()\n",
    "        pred_time = (end - start)\n",
    "\n",
    "        precision, recall= score(self.test[self.target], y_pred)\n",
    "        print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "            fit_time, pred_time, precision[0]/ (precision[0] + precision[1]), recall[1]/ (recall[1] + recall[0]), (y_pred==self.test[self.target]).sum()/len(y_pred)))\n",
    "    \n",
    "    def GradientBoostingClassifier(self, n_estimators = 150 , max_depth = 11):\n",
    "        \n",
    "        gb = GradientBoostingClassifier(n_estimators=150, max_depth=11)\n",
    "\n",
    "        start = time.time()\n",
    "        gb_model = gb.fit(pd.DataFrame(self.vect_train), self.train[self.target])\n",
    "        end = time.time()\n",
    "        fit_time = (end - start)\n",
    "        \n",
    "        start = time.time()\n",
    "        y_pred = gb_model.predict(pd.DataFrame(self.vect_test))\n",
    "        end = time.time()\n",
    "        pred_time = (end - start)\n",
    "\n",
    "        precision, recall= score(self.test[self.target], y_pred)\n",
    "        print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "            fit_time, pred_time, precision[0]/ (precision[0] + precision[1]), recall[1]/ (recall[1] + recall[0]), (y_pred==self.test[self.target]).sum()/len(y_pred)))\n",
    "    \n",
    "    def RidgeClassifier(self):\n",
    "        \n",
    "        rc = RidgeClassifier()\n",
    "        \n",
    "        start = time.time()\n",
    "        rc_model = rc.fit(pd.DataFrame(self.vect_train), self.train[self.target])\n",
    "        end = time.time()\n",
    "        fit_time = (end - start)\n",
    "        \n",
    "        start = time.time()\n",
    "        y_pred = rc_model.predict(pd.DataFrame(self.vect_test))\n",
    "        end = time.time()\n",
    "        pred_time = (end - start)\n",
    "\n",
    "        precision, recall= score(self.test[self.target], y_pred)\n",
    "        print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "            fit_time, pred_time, precision[0]/ (precision[0] + precision[1]), recall[1]/ (recall[1] + recall[0]), (y_pred==self.test[self.target]).sum()/len(y_pred)))\n",
    "    \n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6469b1",
   "metadata": {},
   "source": [
    "# creating Vecrtorize class\n",
    "\n",
    "- > The class contains vectorizers like tfidf and count which convert the text into columns which are used for training.\n",
    "\n",
    "- > the methods in the class use the main text in the data and convert into columns(bag of words) and return it to train_predict class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb7de42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectorize(TrainAndPredict):\n",
    "    \n",
    "    def __init__(self, train, test, target):\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.target = target\n",
    "        self.vect_train = None\n",
    "        self.vect_test = None\n",
    "\n",
    "           \n",
    "    def Tfidf(self, name):\n",
    "        vectorizer = TfidfVectorizer(analyzer = clean_text)\n",
    "        vect_fit = vectorizer.fit(self.train[name])\n",
    "        vect_trans_train = vect_fit.transform(self.train[name])\n",
    "        self.vect_train = vect_trans_train.toarray()\n",
    "        vect_trans_test = vect_fit.transform(self.test[name])\n",
    "        self.vect_test = vect_trans_test.toarray()\n",
    "        \n",
    "        TrainAndPredict(self.train, self.test, self.vect_train, self.vect_test, self.target)\n",
    "    \n",
    "    def Count(self, name):\n",
    "        vectorizer = CountVectorizer(analyzer = clean_text)\n",
    "        vect_fit = vectorizer.fit(self.train[name])\n",
    "        vect_trans_train = vect_fit.transform(self.train[name])\n",
    "        self.vect_train = vect_trans_train.toarray()\n",
    "        vect_trans_test = vect_fit.transform(self.test[name])\n",
    "        self.vect_test = vect_trans_test.toarray()\n",
    "        \n",
    "        TrainAndPredict(self.train, self.test, self.vect_train, self.vect_test, self.target)\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7832b81f",
   "metadata": {},
   "source": [
    "# creating read data class\n",
    "\n",
    "- > with this class we can read the available data with its name as argument\n",
    "\n",
    "- > The split function will split the data for traing and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac2a9c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadData(Vectorize):\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"ReadData instance created\")\n",
    "        self.df  = None\n",
    "        self.train = None\n",
    "        self.test = None\n",
    "        self.target = None\n",
    "    \n",
    "    def Type_csv(self, name, target):\n",
    "        df = pd.read_csv(name)\n",
    "        self.df = df\n",
    "        self.target = target\n",
    "    \n",
    "    def split(self):\n",
    "        self.train = self.df.iloc[:round(0.7 * len(self.df)),:]\n",
    "        self.test = self.df.iloc[round(0.7 * len(self.df)):,:]\n",
    "        \n",
    "        Vectorize(self.train, self.test, self.target)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81cd9298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReadData instance created\n"
     ]
    }
   ],
   "source": [
    "data = ReadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a0853002",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Type_csv(\"airline_sentiment_analysis.csv\", \"airline_sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b446be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e8e54a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Tfidf(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16a7a173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 31.732563495635986 / Predict time: 0.5719819068908691 ---- Precision: 0.9787735849056604 / Recall: 0.597165991902834 / Accuracy: 0.9243212016175621\n"
     ]
    }
   ],
   "source": [
    "data.RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70be7050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 9.735397577285767 / Predict time: 0.1444110870361328 ---- Precision: 0.9838274932614556 / Recall: 0.6356275303643725 / Accuracy: 0.9341421143847487\n"
     ]
    }
   ],
   "source": [
    "data.RidgeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e955e649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
